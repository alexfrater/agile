{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([572, 32])\n",
      "torch.Size([2, 572])\n",
      "torch.Size([100, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0,\"/home/aw1223/agile\")\n",
    "\n",
    "from sdk.models.graphcast import Graphcast\n",
    "from sdk.datasets.fake_data import FakeDataset\n",
    "\n",
    "model = Graphcast()\n",
    "dataset = FakeDataset(\n",
    "                        num_graphs=1, \n",
    "                        num_nodes = 100,\n",
    "                        avg_degree=3,\n",
    "                        num_channels=32,\n",
    "                        edge_dim=32\n",
    "                    )[0]\n",
    "\n",
    "                \n",
    "#IMPORTANT: The order of the inputs in the forward function must match the order of the external inputs identified by the compiler\n",
    "inputs = [dataset.edge_attr,\n",
    "          dataset.edge_index,\n",
    "          dataset.x,\n",
    "          (dataset.edge_attr + 0.1),\n",
    "          dataset.edge_index]\n",
    "\n",
    "print(dataset.edge_attr.shape)\n",
    "print(dataset.edge_index.shape)\n",
    "print(dataset.x.shape)\n",
    "outputs_model, grid_mesh_emb = model(*inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensure inputs match the following list {'g2m_embedder_input_0': None, 'g2m_int_net_input_1': None, 'grid_mesh_embedder_input_0': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 68328.26it/s]\n",
      "72it [00:00, 95264.95it/s]\n",
      "13it [00:00, 68845.90it/s]\n",
      "72it [00:00, 100295.55it/s]\n",
      "13it [00:00, 76260.07it/s]\n",
      "72it [00:00, 99404.18it/s]\n",
      "13it [00:00, 75625.45it/s]\n",
      "72it [00:00, 99930.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename /home/aw1223/timing_tmp.txt\n",
      "Inference job completed in [0.006857990906476975, 0.006787611665421222]ms. Terminating power job...\n",
      "| Component   | Metric           |    Value |\n",
      "|:------------|:-----------------|---------:|\n",
      "| gpu         | Gpu Latency Mean | 0.006858 |\n"
     ]
    }
   ],
   "source": [
    "from sdk.ample import Ample\n",
    "ample = Ample(gpu_sim=True,plot =False)\n",
    "model.to_device('ample',data=inputs)\n",
    "out = model(*inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
